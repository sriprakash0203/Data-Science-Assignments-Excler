{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d72e6823",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8cfec",
   "metadata": {},
   "source": [
    "# Q1-FireForests\n",
    "PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b66ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95e4261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.optimizers import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f984bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a38a89cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('forestfires.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7a5b9",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eadafb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 31)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b18d399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0529217c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['month', 'day', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind',\n",
       "       'rain', 'area', 'dayfri', 'daymon', 'daysat', 'daysun', 'daythu',\n",
       "       'daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', 'monthfeb',\n",
       "       'monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov',\n",
       "       'monthoct', 'monthsep', 'size_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2d149b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23a8f2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90b4d12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.boxplot(df['area'])  #to check outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c622e53",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b33518b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aug    184\n",
       "sep    172\n",
       "mar     54\n",
       "jul     32\n",
       "feb     20\n",
       "jun     17\n",
       "oct     15\n",
       "apr      9\n",
       "dec      9\n",
       "jan      2\n",
       "may      2\n",
       "nov      1\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.month.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ee8d6b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small    378\n",
       "large    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df.size_category.value_counts() # The dataset is biased. Lets remove the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e9d697",
   "metadata": {},
   "source": [
    "# Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0c676ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0      7    0  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     10    5  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     10    2  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3      7    0  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4      7    3  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0              1  \n",
       "1         0              1  \n",
       "2         0              1  \n",
       "3         0              1  \n",
       "4         0              1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing      #We are going to perform label encoding since it is faster than dummy variables\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df.month= label_encoder.fit_transform(df.month) \n",
    "df.day= label_encoder.fit_transform(df.day) \n",
    "df.size_category= label_encoder.fit_transform(df.size_category) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6349e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3734f53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>49</td>\n",
       "      <td>144</td>\n",
       "      <td>42</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>156</td>\n",
       "      <td>42</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>68</td>\n",
       "      <td>30</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>172</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>123</td>\n",
       "      <td>54</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>71</td>\n",
       "      <td>141</td>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>168</td>\n",
       "      <td>122</td>\n",
       "      <td>80</td>\n",
       "      <td>156</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     month  day  FFMC  DMC   DC  ISI  temp  RH  wind  rain  ...  monthdec  \\\n",
       "0        7    0    28   37   41   29    12  34    14     0  ...         0   \n",
       "1       10    5    56   49  144   42    85  16     1     0  ...         0   \n",
       "2       10    2    56   56  156   42    55  16     2     0  ...         0   \n",
       "3        7    0    67   48   33   64    13  72     8     1  ...         0   \n",
       "4        7    3    46   66   46   68    30  73     3     0  ...         0   \n",
       "..     ...  ...   ...  ...  ...  ...   ...  ..   ...   ...  ...       ...   \n",
       "512      1    3     9   71  141    7   172  15     5     0  ...         0   \n",
       "513      1    3     9   71  141    7   123  54    12     0  ...         0   \n",
       "514      1    3     9   71  141    7   116  53    14     0  ...         0   \n",
       "515      1    2    92  168  122   80   156  25     8     0  ...         0   \n",
       "516      9    5     7    2   48    4    34  14     9     0  ...         0   \n",
       "\n",
       "     monthfeb  monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  \\\n",
       "0           0         0         0         0         1         0         0   \n",
       "1           0         0         0         0         0         0         0   \n",
       "2           0         0         0         0         0         0         0   \n",
       "3           0         0         0         0         1         0         0   \n",
       "4           0         0         0         0         1         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         0         1   \n",
       "\n",
       "     monthoct  monthsep  \n",
       "0           0         0  \n",
       "1           1         0  \n",
       "2           1         0  \n",
       "3           0         0  \n",
       "4           0         0  \n",
       "..        ...       ...  \n",
       "512         0         0  \n",
       "513         0         0  \n",
       "514         0         0  \n",
       "515         0         0  \n",
       "516         0         0  \n",
       "\n",
       "[517 rows x 30 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder_x=LabelEncoder()\n",
    "x=x.apply(LabelEncoder().fit_transform)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0d80fa4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     size_category\n",
       "0                1\n",
       "1                1\n",
       "2                1\n",
       "3                1\n",
       "4                1\n",
       "..             ...\n",
       "512              0\n",
       "513              0\n",
       "514              0\n",
       "515              1\n",
       "516              1\n",
       "\n",
       "[517 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(y)\n",
    "label_encoder_y = LabelEncoder()\n",
    "y = y.apply(LabelEncoder().fit_transform)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f0e6327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=30,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(8,  kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1,  kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d149e648",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "16528db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "35/35 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.8006 - val_loss: 0.5895 - val_accuracy: 0.7251\n",
      "Epoch 2/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8786 - val_loss: 0.3550 - val_accuracy: 0.8012\n",
      "Epoch 3/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.1789 - accuracy: 0.9509 - val_loss: 0.2029 - val_accuracy: 0.8947\n",
      "Epoch 4/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9711 - val_loss: 0.1771 - val_accuracy: 0.9064\n",
      "Epoch 5/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0774 - accuracy: 0.9798 - val_loss: 0.1417 - val_accuracy: 0.9415\n",
      "Epoch 6/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0766 - accuracy: 0.9798 - val_loss: 0.1431 - val_accuracy: 0.9474\n",
      "Epoch 7/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9855 - val_loss: 0.1280 - val_accuracy: 0.9474\n",
      "Epoch 8/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0691 - accuracy: 0.9740 - val_loss: 0.1403 - val_accuracy: 0.9532\n",
      "Epoch 9/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9827 - val_loss: 0.1729 - val_accuracy: 0.9181\n",
      "Epoch 10/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0631 - accuracy: 0.9827 - val_loss: 0.1204 - val_accuracy: 0.9532\n",
      "Epoch 11/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0532 - accuracy: 0.9798 - val_loss: 0.3095 - val_accuracy: 0.8713\n",
      "Epoch 12/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0594 - accuracy: 0.9740 - val_loss: 0.1159 - val_accuracy: 0.9532\n",
      "Epoch 13/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9711 - val_loss: 0.1599 - val_accuracy: 0.9240\n",
      "Epoch 14/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.1134 - val_accuracy: 0.9532\n",
      "Epoch 15/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9798 - val_loss: 0.1080 - val_accuracy: 0.9415\n",
      "Epoch 16/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0577 - accuracy: 0.9798 - val_loss: 0.1083 - val_accuracy: 0.9474\n",
      "Epoch 17/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0544 - accuracy: 0.9769 - val_loss: 0.1676 - val_accuracy: 0.9240\n",
      "Epoch 18/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9827 - val_loss: 0.1750 - val_accuracy: 0.9123\n",
      "Epoch 19/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9827 - val_loss: 0.1069 - val_accuracy: 0.9474\n",
      "Epoch 20/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9827 - val_loss: 0.1516 - val_accuracy: 0.9298\n",
      "Epoch 21/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9798 - val_loss: 0.1657 - val_accuracy: 0.9298\n",
      "Epoch 22/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9769 - val_loss: 0.1231 - val_accuracy: 0.9474\n",
      "Epoch 23/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9827 - val_loss: 0.1260 - val_accuracy: 0.9415\n",
      "Epoch 24/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0409 - accuracy: 0.9855 - val_loss: 0.1122 - val_accuracy: 0.9474\n",
      "Epoch 25/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9798 - val_loss: 0.1074 - val_accuracy: 0.9474\n",
      "Epoch 26/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0459 - accuracy: 0.9855 - val_loss: 0.1371 - val_accuracy: 0.9357\n",
      "Epoch 27/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9855 - val_loss: 0.1069 - val_accuracy: 0.9298\n",
      "Epoch 28/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.1292 - val_accuracy: 0.9415\n",
      "Epoch 29/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0469 - accuracy: 0.9798 - val_loss: 0.1151 - val_accuracy: 0.9357\n",
      "Epoch 30/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9798 - val_loss: 0.1204 - val_accuracy: 0.9415\n",
      "Epoch 31/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9855 - val_loss: 0.1689 - val_accuracy: 0.9240\n",
      "Epoch 32/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.9798 - val_loss: 0.1654 - val_accuracy: 0.9298\n",
      "Epoch 33/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.9798 - val_loss: 0.1147 - val_accuracy: 0.9298\n",
      "Epoch 34/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9827 - val_loss: 0.1558 - val_accuracy: 0.9298\n",
      "Epoch 35/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0340 - accuracy: 0.9855 - val_loss: 0.1690 - val_accuracy: 0.9357\n",
      "Epoch 36/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9884 - val_loss: 0.1244 - val_accuracy: 0.9357\n",
      "Epoch 37/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9884 - val_loss: 0.1704 - val_accuracy: 0.9357\n",
      "Epoch 38/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9855 - val_loss: 0.1421 - val_accuracy: 0.9357\n",
      "Epoch 39/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0349 - accuracy: 0.9855 - val_loss: 0.1219 - val_accuracy: 0.9240\n",
      "Epoch 40/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0363 - accuracy: 0.9855 - val_loss: 0.1512 - val_accuracy: 0.9357\n",
      "Epoch 41/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0351 - accuracy: 0.9827 - val_loss: 0.1306 - val_accuracy: 0.9298\n",
      "Epoch 42/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0451 - accuracy: 0.9769 - val_loss: 0.2701 - val_accuracy: 0.9181\n",
      "Epoch 43/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0341 - accuracy: 0.9827 - val_loss: 0.1357 - val_accuracy: 0.9298\n",
      "Epoch 44/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9827 - val_loss: 0.1371 - val_accuracy: 0.9298\n",
      "Epoch 45/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0450 - accuracy: 0.9769 - val_loss: 0.1290 - val_accuracy: 0.9240\n",
      "Epoch 46/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0477 - accuracy: 0.9769 - val_loss: 0.1268 - val_accuracy: 0.9240\n",
      "Epoch 47/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9798 - val_loss: 0.1843 - val_accuracy: 0.9298\n",
      "Epoch 48/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0423 - accuracy: 0.9798 - val_loss: 0.1819 - val_accuracy: 0.9298\n",
      "Epoch 49/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9884 - val_loss: 0.1542 - val_accuracy: 0.9357\n",
      "Epoch 50/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0330 - accuracy: 0.9827 - val_loss: 0.1584 - val_accuracy: 0.9357\n",
      "Epoch 51/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0292 - accuracy: 0.9855 - val_loss: 0.1861 - val_accuracy: 0.9298\n",
      "Epoch 52/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9884 - val_loss: 0.1956 - val_accuracy: 0.9298\n",
      "Epoch 53/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0291 - accuracy: 0.9855 - val_loss: 0.1719 - val_accuracy: 0.9357\n",
      "Epoch 54/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 0.9884 - val_loss: 0.2224 - val_accuracy: 0.9298\n",
      "Epoch 55/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0392 - accuracy: 0.9798 - val_loss: 0.3006 - val_accuracy: 0.9181\n",
      "Epoch 56/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9798 - val_loss: 0.2418 - val_accuracy: 0.9240\n",
      "Epoch 57/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9855 - val_loss: 0.1585 - val_accuracy: 0.9298\n",
      "Epoch 58/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0277 - accuracy: 0.9827 - val_loss: 0.1803 - val_accuracy: 0.9357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9884 - val_loss: 0.1681 - val_accuracy: 0.9298\n",
      "Epoch 60/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0271 - accuracy: 0.9855 - val_loss: 0.1838 - val_accuracy: 0.9357\n",
      "Epoch 61/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0274 - accuracy: 0.9855 - val_loss: 0.2142 - val_accuracy: 0.9298\n",
      "Epoch 62/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 0.9855 - val_loss: 0.1620 - val_accuracy: 0.9240\n",
      "Epoch 63/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9884 - val_loss: 0.2227 - val_accuracy: 0.9298\n",
      "Epoch 64/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.1627 - val_accuracy: 0.9240\n",
      "Epoch 65/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9855 - val_loss: 0.1836 - val_accuracy: 0.9357\n",
      "Epoch 66/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0244 - accuracy: 0.9884 - val_loss: 0.2059 - val_accuracy: 0.9474\n",
      "Epoch 67/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9913 - val_loss: 0.2496 - val_accuracy: 0.9298\n",
      "Epoch 68/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9913 - val_loss: 0.3080 - val_accuracy: 0.9357\n",
      "Epoch 69/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 0.9942 - val_loss: 0.1779 - val_accuracy: 0.9298\n",
      "Epoch 70/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.2106 - val_accuracy: 0.9474\n",
      "Epoch 71/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0242 - accuracy: 0.9942 - val_loss: 0.2437 - val_accuracy: 0.9357\n",
      "Epoch 72/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9942 - val_loss: 0.2198 - val_accuracy: 0.9474\n",
      "Epoch 73/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9855 - val_loss: 0.2380 - val_accuracy: 0.9415\n",
      "Epoch 74/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.2798 - val_accuracy: 0.9415\n",
      "Epoch 75/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9913 - val_loss: 0.3053 - val_accuracy: 0.9357\n",
      "Epoch 76/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9884 - val_loss: 0.2546 - val_accuracy: 0.9415\n",
      "Epoch 77/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 0.9942 - val_loss: 0.2433 - val_accuracy: 0.9474\n",
      "Epoch 78/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0204 - accuracy: 0.9942 - val_loss: 0.2660 - val_accuracy: 0.9357\n",
      "Epoch 79/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.2286 - val_accuracy: 0.9415\n",
      "Epoch 80/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9913 - val_loss: 0.4539 - val_accuracy: 0.9064\n",
      "Epoch 81/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9913 - val_loss: 0.2282 - val_accuracy: 0.9415\n",
      "Epoch 82/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0211 - accuracy: 0.9913 - val_loss: 0.3422 - val_accuracy: 0.9357\n",
      "Epoch 83/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9942 - val_loss: 0.3107 - val_accuracy: 0.9357\n",
      "Epoch 84/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0287 - accuracy: 0.9913 - val_loss: 0.2816 - val_accuracy: 0.9357\n",
      "Epoch 85/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0239 - accuracy: 0.9884 - val_loss: 0.2357 - val_accuracy: 0.9415\n",
      "Epoch 86/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.2892 - val_accuracy: 0.9357\n",
      "Epoch 87/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.2198 - val_accuracy: 0.9357\n",
      "Epoch 88/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9913 - val_loss: 0.3045 - val_accuracy: 0.9357\n",
      "Epoch 89/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0214 - accuracy: 0.9971 - val_loss: 0.2688 - val_accuracy: 0.9415\n",
      "Epoch 90/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9884 - val_loss: 0.2584 - val_accuracy: 0.9474\n",
      "Epoch 91/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.2163 - val_accuracy: 0.9357\n",
      "Epoch 92/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9913 - val_loss: 0.4054 - val_accuracy: 0.9240\n",
      "Epoch 93/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0286 - accuracy: 0.9884 - val_loss: 0.2902 - val_accuracy: 0.9357\n",
      "Epoch 94/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0198 - accuracy: 0.9913 - val_loss: 0.2782 - val_accuracy: 0.9357\n",
      "Epoch 95/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0172 - accuracy: 0.9884 - val_loss: 0.2533 - val_accuracy: 0.9474\n",
      "Epoch 96/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0210 - accuracy: 0.9913 - val_loss: 0.2415 - val_accuracy: 0.9415\n",
      "Epoch 97/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0298 - accuracy: 0.9884 - val_loss: 0.3838 - val_accuracy: 0.9357\n",
      "Epoch 98/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9942 - val_loss: 0.2949 - val_accuracy: 0.9357\n",
      "Epoch 99/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.2268 - val_accuracy: 0.9357\n",
      "Epoch 100/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9913 - val_loss: 0.2510 - val_accuracy: 0.9415\n",
      "Epoch 101/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.2775 - val_accuracy: 0.9415\n",
      "Epoch 102/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0195 - accuracy: 0.9942 - val_loss: 0.3746 - val_accuracy: 0.9357\n",
      "Epoch 103/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9971 - val_loss: 0.2391 - val_accuracy: 0.9298\n",
      "Epoch 104/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9884 - val_loss: 0.2771 - val_accuracy: 0.9474\n",
      "Epoch 105/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.2786 - val_accuracy: 0.9415\n",
      "Epoch 106/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9913 - val_loss: 0.3236 - val_accuracy: 0.9357\n",
      "Epoch 107/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.3727 - val_accuracy: 0.9298\n",
      "Epoch 108/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0272 - accuracy: 0.9884 - val_loss: 0.3769 - val_accuracy: 0.9357\n",
      "Epoch 109/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9884 - val_loss: 0.3340 - val_accuracy: 0.9357\n",
      "Epoch 110/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.3364 - val_accuracy: 0.9357\n",
      "Epoch 111/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9942 - val_loss: 0.3161 - val_accuracy: 0.9357\n",
      "Epoch 112/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9913 - val_loss: 0.3039 - val_accuracy: 0.9357\n",
      "Epoch 113/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0202 - accuracy: 0.9913 - val_loss: 0.2944 - val_accuracy: 0.9357\n",
      "Epoch 114/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9884 - val_loss: 0.4415 - val_accuracy: 0.9181\n",
      "Epoch 115/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0163 - accuracy: 0.9942 - val_loss: 0.2532 - val_accuracy: 0.9357\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.3477 - val_accuracy: 0.9298\n",
      "Epoch 117/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0232 - accuracy: 0.9884 - val_loss: 0.2573 - val_accuracy: 0.9357\n",
      "Epoch 118/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.3190 - val_accuracy: 0.9298\n",
      "Epoch 119/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 0.9942 - val_loss: 0.3863 - val_accuracy: 0.9298\n",
      "Epoch 120/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9913 - val_loss: 0.2474 - val_accuracy: 0.9181\n",
      "Epoch 121/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 0.3404 - val_accuracy: 0.9357\n",
      "Epoch 122/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9855 - val_loss: 0.2453 - val_accuracy: 0.9123\n",
      "Epoch 123/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 0.3924 - val_accuracy: 0.9357\n",
      "Epoch 124/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0303 - accuracy: 0.9884 - val_loss: 0.4083 - val_accuracy: 0.9357\n",
      "Epoch 125/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9913 - val_loss: 0.2506 - val_accuracy: 0.9357\n",
      "Epoch 126/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9942 - val_loss: 0.3926 - val_accuracy: 0.9357\n",
      "Epoch 127/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0208 - accuracy: 0.9971 - val_loss: 0.3213 - val_accuracy: 0.9298\n",
      "Epoch 128/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 0.9913 - val_loss: 0.3200 - val_accuracy: 0.9298\n",
      "Epoch 129/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9884 - val_loss: 0.2695 - val_accuracy: 0.9474\n",
      "Epoch 130/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9884 - val_loss: 0.2350 - val_accuracy: 0.9181\n",
      "Epoch 131/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9884 - val_loss: 0.3253 - val_accuracy: 0.9357\n",
      "Epoch 132/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9942 - val_loss: 0.3110 - val_accuracy: 0.9357\n",
      "Epoch 133/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.9884 - val_loss: 0.2456 - val_accuracy: 0.9298\n",
      "Epoch 134/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 0.2472 - val_accuracy: 0.9298\n",
      "Epoch 135/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9913 - val_loss: 0.3052 - val_accuracy: 0.9357\n",
      "Epoch 136/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 0.9855 - val_loss: 0.2580 - val_accuracy: 0.9181\n",
      "Epoch 137/150\n",
      "35/35 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9855 - val_loss: 0.2909 - val_accuracy: 0.9357\n",
      "Epoch 138/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9913 - val_loss: 0.2668 - val_accuracy: 0.9474\n",
      "Epoch 139/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 0.3270 - val_accuracy: 0.9357\n",
      "Epoch 140/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0166 - accuracy: 0.9942 - val_loss: 0.3116 - val_accuracy: 0.9298\n",
      "Epoch 141/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0193 - accuracy: 0.9913 - val_loss: 0.2722 - val_accuracy: 0.9415\n",
      "Epoch 142/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9884 - val_loss: 0.3054 - val_accuracy: 0.9415\n",
      "Epoch 143/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0218 - accuracy: 0.9884 - val_loss: 0.3886 - val_accuracy: 0.9298\n",
      "Epoch 144/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0183 - accuracy: 0.9913 - val_loss: 0.2645 - val_accuracy: 0.9415\n",
      "Epoch 145/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0230 - accuracy: 0.9884 - val_loss: 0.2879 - val_accuracy: 0.9357\n",
      "Epoch 146/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9913 - val_loss: 0.4339 - val_accuracy: 0.9298\n",
      "Epoch 147/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0241 - accuracy: 0.9942 - val_loss: 0.3104 - val_accuracy: 0.9298\n",
      "Epoch 148/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.2852 - val_accuracy: 0.9415\n",
      "Epoch 149/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0157 - accuracy: 0.9942 - val_loss: 0.3442 - val_accuracy: 0.9357\n",
      "Epoch 150/150\n",
      "35/35 [==============================] - 0s 1ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 0.2517 - val_accuracy: 0.9298\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(x, y, validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "692aa7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 905us/step - loss: 0.0983 - accuracy: 0.9729\n",
      "accuracy: 97.29%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x, y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "18c0ab47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "40404591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1162241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = StandardScaler()\n",
    "a.fit(x)\n",
    "X_standardized = a.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "06fbf242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "      <td>5.170000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.874674e-17</td>\n",
       "      <td>5.110891e-17</td>\n",
       "      <td>-9.019220e-17</td>\n",
       "      <td>2.594099e-16</td>\n",
       "      <td>6.442300e-17</td>\n",
       "      <td>-8.718579e-17</td>\n",
       "      <td>-7.816657e-17</td>\n",
       "      <td>6.485249e-17</td>\n",
       "      <td>4.724353e-18</td>\n",
       "      <td>-4.790924e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>7.179943e-16</td>\n",
       "      <td>-1.933764e-16</td>\n",
       "      <td>-2.260174e-17</td>\n",
       "      <td>1.352883e-17</td>\n",
       "      <td>1.169277e-16</td>\n",
       "      <td>2.265542e-16</td>\n",
       "      <td>-2.596515e-16</td>\n",
       "      <td>1.443075e-16</td>\n",
       "      <td>6.253326e-16</td>\n",
       "      <td>4.024290e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "      <td>1.000969e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.317959e+00</td>\n",
       "      <td>-1.423121e+00</td>\n",
       "      <td>-2.755520e+00</td>\n",
       "      <td>-2.134531e+00</td>\n",
       "      <td>-2.119754e+00</td>\n",
       "      <td>-2.133725e+00</td>\n",
       "      <td>-2.036890e+00</td>\n",
       "      <td>-1.713964e+00</td>\n",
       "      <td>-2.004018e+00</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.089076e+00</td>\n",
       "      <td>-9.031536e-01</td>\n",
       "      <td>-5.025653e-01</td>\n",
       "      <td>-8.010724e-01</td>\n",
       "      <td>-7.605602e-01</td>\n",
       "      <td>-6.928003e-01</td>\n",
       "      <td>-7.181571e-01</td>\n",
       "      <td>-7.060079e-01</td>\n",
       "      <td>-7.499909e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.533922e-02</td>\n",
       "      <td>1.367805e-01</td>\n",
       "      <td>1.039993e-01</td>\n",
       "      <td>1.234588e-01</td>\n",
       "      <td>1.959092e-01</td>\n",
       "      <td>-4.438437e-02</td>\n",
       "      <td>4.755898e-02</td>\n",
       "      <td>-1.390326e-01</td>\n",
       "      <td>2.425585e-03</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>-7.060812e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>6.567476e-01</td>\n",
       "      <td>6.672378e-01</td>\n",
       "      <td>8.168572e-01</td>\n",
       "      <td>7.999952e-01</td>\n",
       "      <td>6.400547e-01</td>\n",
       "      <td>7.494654e-01</td>\n",
       "      <td>5.539372e-01</td>\n",
       "      <td>5.040366e-01</td>\n",
       "      <td>-1.100649e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.331035e-01</td>\n",
       "      <td>-2.006027e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-2.568645e-01</td>\n",
       "      <td>-1.843909e-01</td>\n",
       "      <td>-3.415123e-01</td>\n",
       "      <td>-6.231770e-02</td>\n",
       "      <td>-4.402255e-02</td>\n",
       "      <td>-1.728597e-01</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.199754e+00</td>\n",
       "      <td>1.696682e+00</td>\n",
       "      <td>1.793715e+00</td>\n",
       "      <td>1.670271e+00</td>\n",
       "      <td>1.538322e+00</td>\n",
       "      <td>2.117002e+00</td>\n",
       "      <td>2.025659e+00</td>\n",
       "      <td>2.947833e+00</td>\n",
       "      <td>3.012092e+00</td>\n",
       "      <td>1.354679e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.512952e+00</td>\n",
       "      <td>4.984977e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>3.893103e+00</td>\n",
       "      <td>5.423261e+00</td>\n",
       "      <td>2.928152e+00</td>\n",
       "      <td>1.604681e+01</td>\n",
       "      <td>2.271563e+01</td>\n",
       "      <td>5.785038e+00</td>\n",
       "      <td>1.416268e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -4.874674e-17  5.110891e-17 -9.019220e-17  2.594099e-16  6.442300e-17   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.317959e+00 -1.423121e+00 -2.755520e+00 -2.134531e+00 -2.119754e+00   \n",
       "25%   -1.089076e+00 -9.031536e-01 -5.025653e-01 -8.010724e-01 -7.605602e-01   \n",
       "50%    5.533922e-02  1.367805e-01  1.039993e-01  1.234588e-01  1.959092e-01   \n",
       "75%    1.199754e+00  6.567476e-01  6.672378e-01  8.168572e-01  7.999952e-01   \n",
       "max    1.199754e+00  1.696682e+00  1.793715e+00  1.670271e+00  1.538322e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean  -8.718579e-17 -7.816657e-17  6.485249e-17  4.724353e-18 -4.790924e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -2.133725e+00 -2.036890e+00 -1.713964e+00 -2.004018e+00 -1.100649e-01   \n",
       "25%   -6.928003e-01 -7.181571e-01 -7.060079e-01 -7.499909e-01 -1.100649e-01   \n",
       "50%   -4.438437e-02  4.755898e-02 -1.390326e-01  2.425585e-03 -1.100649e-01   \n",
       "75%    6.400547e-01  7.494654e-01  5.539372e-01  5.040366e-01 -1.100649e-01   \n",
       "max    2.117002e+00  2.025659e+00  2.947833e+00  3.012092e+00  1.354679e+01   \n",
       "\n",
       "       ...            20            21            22            23  \\\n",
       "count  ...  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   ...  7.179943e-16 -1.933764e-16 -2.260174e-17  1.352883e-17   \n",
       "std    ...  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "25%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "50%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "75%    ... -1.331035e-01 -2.006027e-01 -6.231770e-02 -2.568645e-01   \n",
       "max    ...  7.512952e+00  4.984977e+00  1.604681e+01  3.893103e+00   \n",
       "\n",
       "                 24            25            26            27            28  \\\n",
       "count  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02  5.170000e+02   \n",
       "mean   1.169277e-16  2.265542e-16 -2.596515e-16  1.443075e-16  6.253326e-16   \n",
       "std    1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00  1.000969e+00   \n",
       "min   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "25%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "50%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "75%   -1.843909e-01 -3.415123e-01 -6.231770e-02 -4.402255e-02 -1.728597e-01   \n",
       "max    5.423261e+00  2.928152e+00  1.604681e+01  2.271563e+01  5.785038e+00   \n",
       "\n",
       "                 29  \n",
       "count  5.170000e+02  \n",
       "mean   4.024290e-16  \n",
       "std    1.000969e+00  \n",
       "min   -7.060812e-01  \n",
       "25%   -7.060812e-01  \n",
       "50%   -7.060812e-01  \n",
       "75%    1.416268e+00  \n",
       "max    1.416268e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_standardized).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1889c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.923 total time=   0.6s\n",
      "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.981 total time=   0.7s\n",
      "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.951 total time=   0.6s\n",
      "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
      "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.893 total time=   0.8s\n",
      "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=1.000 total time=   1.6s\n",
      "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.952 total time=   1.6s\n",
      "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.932 total time=   1.5s\n",
      "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.913 total time=   1.5s\n",
      "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
      "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.893 total time=   1.6s\n",
      "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=1.000 total time=   2.9s\n",
      "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.971 total time=   2.8s\n",
      "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.981 total time=   2.9s\n",
      "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.932 total time=   3.3s\n",
      "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
      "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.922 total time=   2.9s\n",
      "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.942 total time=   0.7s\n",
      "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.971 total time=   0.5s\n",
      "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.922 total time=   0.6s\n",
      "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
      "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.922 total time=   0.6s\n",
      "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=1.000 total time=   1.1s\n",
      "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.894 total time=   1.0s\n",
      "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.981 total time=   1.0s\n",
      "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=0.951 total time=   1.1s\n",
      "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
      "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.913 total time=   1.2s\n",
      "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   1.8s\n",
      "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.962 total time=   1.8s\n",
      "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.971 total time=   2.3s\n",
      "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=0.942 total time=   1.9s\n",
      "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
      "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.913 total time=   2.1s\n",
      "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.962 total time=   0.4s\n",
      "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.961 total time=   0.5s\n",
      "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E7C1B04EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.942 total time=   0.5s\n",
      "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001E7C0922310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.883 total time=   0.5s\n",
      "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.952 total time=   1.0s\n",
      "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.990 total time=   0.7s\n",
      "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.932 total time=   0.7s\n",
      "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
      "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.932 total time=   0.9s\n",
      "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=1.000 total time=   1.0s\n",
      "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.962 total time=   1.0s\n",
      "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.971 total time=   1.1s\n",
      "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=0.951 total time=   1.1s\n",
      "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
      "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.932 total time=   1.2s\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\\\n",
    "    \n",
    "    adam=Adam(lr=0.01)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
    "# Define the grid search parameters\n",
    "batch_size = [10,20,40]\n",
    "epochs = [10,50,100]\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
    "# Build and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c06134e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.963181471824646, using {'batch_size': 40, 'epochs': 100}\n",
      "0.9496639251708985,0.03843826615969345 with: {'batch_size': 10, 'epochs': 10}\n",
      "0.9379574298858643,0.036671916564909625 with: {'batch_size': 10, 'epochs': 50}\n",
      "0.9612210631370545,0.029466738193148243 with: {'batch_size': 10, 'epochs': 100}\n",
      "0.951568329334259,0.030046085329134605 with: {'batch_size': 20, 'epochs': 10}\n",
      "0.9477782011032104,0.03979974177691215 with: {'batch_size': 20, 'epochs': 50}\n",
      "0.9573562264442443,0.029201177493081668 with: {'batch_size': 20, 'epochs': 100}\n",
      "0.9495892405509949,0.03807347750067746 with: {'batch_size': 40, 'epochs': 10}\n",
      "0.9612583994865418,0.02876988194052299 with: {'batch_size': 40, 'epochs': 50}\n",
      "0.963181471824646,0.02247139442935497 with: {'batch_size': 40, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2f93cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "def create_model(learning_rate,dropout_rate):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = 'normal',activation = 'relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1c7e760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 1/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 2/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.750 total time=   0.4s\n",
      "[CV 3/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 3/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.524 total time=   0.4s\n",
      "[CV 4/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 4/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.718 total time=   0.4s\n",
      "[CV 5/5; 1/9] START dropout_rate=0.0, learning_rate=0.001.......................\n",
      "[CV 5/5; 1/9] END dropout_rate=0.0, learning_rate=0.001;, score=0.699 total time=   0.4s\n",
      "[CV 1/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 1/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 2/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.913 total time=   0.4s\n",
      "[CV 3/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 3/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.951 total time=   0.4s\n",
      "[CV 4/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 4/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.942 total time=   0.4s\n",
      "[CV 5/5; 2/9] START dropout_rate=0.0, learning_rate=0.01........................\n",
      "[CV 5/5; 2/9] END dropout_rate=0.0, learning_rate=0.01;, score=0.913 total time=   0.6s\n",
      "[CV 1/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 1/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 2/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.942 total time=   0.4s\n",
      "[CV 3/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 3/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.981 total time=   0.4s\n",
      "[CV 4/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 4/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.893 total time=   0.4s\n",
      "[CV 5/5; 3/9] START dropout_rate=0.0, learning_rate=0.1.........................\n",
      "[CV 5/5; 3/9] END dropout_rate=0.0, learning_rate=0.1;, score=0.922 total time=   0.4s\n",
      "[CV 1/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 1/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 2/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.750 total time=   0.4s\n",
      "[CV 3/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 3/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.524 total time=   0.5s\n",
      "[CV 4/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 4/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.680 total time=   0.5s\n",
      "[CV 5/5; 4/9] START dropout_rate=0.1, learning_rate=0.001.......................\n",
      "[CV 5/5; 4/9] END dropout_rate=0.1, learning_rate=0.001;, score=0.699 total time=   0.5s\n",
      "[CV 1/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 1/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 2/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.904 total time=   0.5s\n",
      "[CV 3/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 3/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.883 total time=   0.5s\n",
      "[CV 4/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 4/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 5/9] START dropout_rate=0.1, learning_rate=0.01........................\n",
      "[CV 5/5; 5/9] END dropout_rate=0.1, learning_rate=0.01;, score=0.942 total time=   0.4s\n",
      "[CV 1/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 1/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 2/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.981 total time=   0.4s\n",
      "[CV 3/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 3/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.981 total time=   0.5s\n",
      "[CV 4/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 4/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.961 total time=   0.4s\n",
      "[CV 5/5; 6/9] START dropout_rate=0.1, learning_rate=0.1.........................\n",
      "[CV 5/5; 6/9] END dropout_rate=0.1, learning_rate=0.1;, score=0.922 total time=   0.4s\n",
      "[CV 1/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 1/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 2/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.750 total time=   0.6s\n",
      "[CV 3/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 3/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.524 total time=   0.4s\n",
      "[CV 4/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 4/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.680 total time=   0.4s\n",
      "[CV 5/5; 7/9] START dropout_rate=0.2, learning_rate=0.001.......................\n",
      "[CV 5/5; 7/9] END dropout_rate=0.2, learning_rate=0.001;, score=0.699 total time=   0.4s\n",
      "[CV 1/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 1/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 2/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.923 total time=   0.5s\n",
      "[CV 3/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 3/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.932 total time=   0.4s\n",
      "[CV 4/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 4/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.932 total time=   0.4s\n",
      "[CV 5/5; 8/9] START dropout_rate=0.2, learning_rate=0.01........................\n",
      "[CV 5/5; 8/9] END dropout_rate=0.2, learning_rate=0.01;, score=0.951 total time=   0.5s\n",
      "[CV 1/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 1/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 2/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.962 total time=   0.4s\n",
      "[CV 3/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 3/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.971 total time=   0.6s\n",
      "[CV 4/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 4/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.942 total time=   0.4s\n",
      "[CV 5/5; 9/9] START dropout_rate=0.2, learning_rate=0.1.........................\n",
      "[CV 5/5; 9/9] END dropout_rate=0.2, learning_rate=0.1;, score=0.893 total time=   0.5s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a9099fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9689693808555603, using {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7383495211601258,0.1525569895928302 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
      "0.9438573598861695,0.031980563368100644 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
      "0.9476848363876342,0.038624058291867075 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "0.9322255373001098,0.03965884940269086 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "0.9689693808555603,0.026355767189299335 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "0.7305825233459473,0.15435061319000673 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "0.9477221846580506,0.02773530861802744 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "0.9534727215766907,0.03550339707116939 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a520de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation_function,init):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4,input_dim = 30,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ddaf30b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 1/5; 1/12] END activation_function=softmax, init=uniform;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 2/5; 1/12] END activation_function=softmax, init=uniform;, score=0.750 total time=   0.5s\n",
      "[CV 3/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 3/5; 1/12] END activation_function=softmax, init=uniform;, score=0.524 total time=   0.5s\n",
      "[CV 4/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 4/5; 1/12] END activation_function=softmax, init=uniform;, score=0.680 total time=   0.4s\n",
      "[CV 5/5; 1/12] START activation_function=softmax, init=uniform..................\n",
      "[CV 5/5; 1/12] END activation_function=softmax, init=uniform;, score=0.699 total time=   0.4s\n",
      "[CV 1/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 1/5; 2/12] END activation_function=softmax, init=normal;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 2/5; 2/12] END activation_function=softmax, init=normal;, score=0.750 total time=   0.4s\n",
      "[CV 3/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 3/5; 2/12] END activation_function=softmax, init=normal;, score=0.524 total time=   0.6s\n",
      "[CV 4/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 4/5; 2/12] END activation_function=softmax, init=normal;, score=0.680 total time=   0.4s\n",
      "[CV 5/5; 2/12] START activation_function=softmax, init=normal...................\n",
      "[CV 5/5; 2/12] END activation_function=softmax, init=normal;, score=0.699 total time=   0.4s\n",
      "[CV 1/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 1/5; 3/12] END activation_function=softmax, init=zero;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 2/5; 3/12] END activation_function=softmax, init=zero;, score=0.750 total time=   0.4s\n",
      "[CV 3/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 3/5; 3/12] END activation_function=softmax, init=zero;, score=0.524 total time=   0.4s\n",
      "[CV 4/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 4/5; 3/12] END activation_function=softmax, init=zero;, score=0.680 total time=   0.4s\n",
      "[CV 5/5; 3/12] START activation_function=softmax, init=zero.....................\n",
      "[CV 5/5; 3/12] END activation_function=softmax, init=zero;, score=0.699 total time=   0.4s\n",
      "[CV 1/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 1/5; 4/12] END activation_function=relu, init=uniform;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 2/5; 4/12] END activation_function=relu, init=uniform;, score=0.750 total time=   0.4s\n",
      "[CV 3/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 3/5; 4/12] END activation_function=relu, init=uniform;, score=0.524 total time=   0.4s\n",
      "[CV 4/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 4/5; 4/12] END activation_function=relu, init=uniform;, score=0.845 total time=   0.6s\n",
      "[CV 5/5; 4/12] START activation_function=relu, init=uniform.....................\n",
      "[CV 5/5; 4/12] END activation_function=relu, init=uniform;, score=0.699 total time=   0.4s\n",
      "[CV 1/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 1/5; 5/12] END activation_function=relu, init=normal;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 2/5; 5/12] END activation_function=relu, init=normal;, score=0.750 total time=   0.4s\n",
      "[CV 3/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 3/5; 5/12] END activation_function=relu, init=normal;, score=0.524 total time=   0.4s\n",
      "[CV 4/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 4/5; 5/12] END activation_function=relu, init=normal;, score=0.680 total time=   0.4s\n",
      "[CV 5/5; 5/12] START activation_function=relu, init=normal......................\n",
      "[CV 5/5; 5/12] END activation_function=relu, init=normal;, score=0.699 total time=   0.4s\n",
      "[CV 1/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 1/5; 6/12] END activation_function=relu, init=zero;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 2/5; 6/12] END activation_function=relu, init=zero;, score=0.750 total time=   0.4s\n",
      "[CV 3/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 3/5; 6/12] END activation_function=relu, init=zero;, score=0.524 total time=   0.4s\n",
      "[CV 4/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 4/5; 6/12] END activation_function=relu, init=zero;, score=0.680 total time=   0.4s\n",
      "[CV 5/5; 6/12] START activation_function=relu, init=zero........................\n",
      "[CV 5/5; 6/12] END activation_function=relu, init=zero;, score=0.699 total time=   0.6s\n",
      "[CV 1/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 1/5; 7/12] END activation_function=tanh, init=uniform;, score=0.981 total time=   0.4s\n",
      "[CV 2/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 2/5; 7/12] END activation_function=tanh, init=uniform;, score=0.808 total time=   0.4s\n",
      "[CV 3/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 3/5; 7/12] END activation_function=tanh, init=uniform;, score=0.767 total time=   0.4s\n",
      "[CV 4/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 4/5; 7/12] END activation_function=tanh, init=uniform;, score=0.845 total time=   0.4s\n",
      "[CV 5/5; 7/12] START activation_function=tanh, init=uniform.....................\n",
      "[CV 5/5; 7/12] END activation_function=tanh, init=uniform;, score=0.796 total time=   0.4s\n",
      "[CV 1/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 1/5; 8/12] END activation_function=tanh, init=normal;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 2/5; 8/12] END activation_function=tanh, init=normal;, score=0.817 total time=   0.4s\n",
      "[CV 3/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 3/5; 8/12] END activation_function=tanh, init=normal;, score=0.767 total time=   0.4s\n",
      "[CV 4/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 4/5; 8/12] END activation_function=tanh, init=normal;, score=0.864 total time=   0.4s\n",
      "[CV 5/5; 8/12] START activation_function=tanh, init=normal......................\n",
      "[CV 5/5; 8/12] END activation_function=tanh, init=normal;, score=0.825 total time=   0.5s\n",
      "[CV 1/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 1/5; 9/12] END activation_function=tanh, init=zero;, score=1.000 total time=   0.7s\n",
      "[CV 2/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 2/5; 9/12] END activation_function=tanh, init=zero;, score=0.750 total time=   0.5s\n",
      "[CV 3/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 3/5; 9/12] END activation_function=tanh, init=zero;, score=0.524 total time=   0.5s\n",
      "[CV 4/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 4/5; 9/12] END activation_function=tanh, init=zero;, score=0.680 total time=   0.5s\n",
      "[CV 5/5; 9/12] START activation_function=tanh, init=zero........................\n",
      "[CV 5/5; 9/12] END activation_function=tanh, init=zero;, score=0.699 total time=   0.5s\n",
      "[CV 1/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 1/5; 10/12] END activation_function=linear, init=uniform;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 2/5; 10/12] END activation_function=linear, init=uniform;, score=0.788 total time=   0.5s\n",
      "[CV 3/5; 10/12] START activation_function=linear, init=uniform..................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 10/12] END activation_function=linear, init=uniform;, score=0.786 total time=   0.5s\n",
      "[CV 4/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 4/5; 10/12] END activation_function=linear, init=uniform;, score=0.883 total time=   0.5s\n",
      "[CV 5/5; 10/12] START activation_function=linear, init=uniform..................\n",
      "[CV 5/5; 10/12] END activation_function=linear, init=uniform;, score=0.796 total time=   0.4s\n",
      "[CV 1/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 1/5; 11/12] END activation_function=linear, init=normal;, score=0.990 total time=   0.5s\n",
      "[CV 2/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 2/5; 11/12] END activation_function=linear, init=normal;, score=0.808 total time=   0.6s\n",
      "[CV 3/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 3/5; 11/12] END activation_function=linear, init=normal;, score=0.709 total time=   0.4s\n",
      "[CV 4/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 4/5; 11/12] END activation_function=linear, init=normal;, score=0.845 total time=   0.4s\n",
      "[CV 5/5; 11/12] START activation_function=linear, init=normal...................\n",
      "[CV 5/5; 11/12] END activation_function=linear, init=normal;, score=0.854 total time=   0.4s\n",
      "[CV 1/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 1/5; 12/12] END activation_function=linear, init=zero;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 2/5; 12/12] END activation_function=linear, init=zero;, score=0.750 total time=   0.5s\n",
      "[CV 3/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 3/5; 12/12] END activation_function=linear, init=zero;, score=0.524 total time=   0.5s\n",
      "[CV 4/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 4/5; 12/12] END activation_function=linear, init=zero;, score=0.680 total time=   0.4s\n",
      "[CV 5/5; 12/12] START activation_function=linear, init=zero.....................\n",
      "[CV 5/5; 12/12] END activation_function=linear, init=zero;, score=0.699 total time=   0.4s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "param_grids = dict(activation_function = activation_function,init = init)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ba0a9f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.8547236800193787, using {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
      "0.7635922431945801,0.15753605284927072 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'relu', 'init': 'zero'}\n",
      "0.8392457127571106,0.07501307636084516 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
      "0.8547236800193787,0.07894166823811542 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
      "0.8508962035179138,0.08288822387694161 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "0.8411687850952149,0.09067572218529517 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "0.7305825233459473,0.15435061319000673 with: {'activation_function': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3343b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 30,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'sigmoid'))\n",
    "    \n",
    "    adam = Adam(lr = 0.001)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c046db56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV 1/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 1/5; 1/9] END .........neuron1=4, neuron2=2;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 2/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.750 total time=   0.5s\n",
      "[CV 3/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 3/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.660 total time=   0.6s\n",
      "[CV 4/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 4/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.680 total time=   0.5s\n",
      "[CV 5/5; 1/9] START neuron1=4, neuron2=2........................................\n",
      "[CV 5/5; 1/9] END .........neuron1=4, neuron2=2;, score=0.689 total time=   0.5s\n",
      "[CV 1/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 1/5; 2/9] END .........neuron1=4, neuron2=4;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 2/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.750 total time=   0.4s\n",
      "[CV 3/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 3/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.592 total time=   0.5s\n",
      "[CV 4/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 4/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.767 total time=   0.4s\n",
      "[CV 5/5; 2/9] START neuron1=4, neuron2=4........................................\n",
      "[CV 5/5; 2/9] END .........neuron1=4, neuron2=4;, score=0.738 total time=   0.5s\n",
      "[CV 1/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 1/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.981 total time=   0.5s\n",
      "[CV 2/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 2/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.760 total time=   0.5s\n",
      "[CV 3/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 3/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.660 total time=   0.4s\n",
      "[CV 4/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 4/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.777 total time=   0.7s\n",
      "[CV 5/5; 3/9] START neuron1=4, neuron2=8........................................\n",
      "[CV 5/5; 3/9] END .........neuron1=4, neuron2=8;, score=0.777 total time=   0.4s\n",
      "[CV 1/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 1/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.971 total time=   0.5s\n",
      "[CV 2/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 2/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.827 total time=   0.4s\n",
      "[CV 3/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 3/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.748 total time=   0.4s\n",
      "[CV 4/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 4/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.806 total time=   0.4s\n",
      "[CV 5/5; 4/9] START neuron1=8, neuron2=2........................................\n",
      "[CV 5/5; 4/9] END .........neuron1=8, neuron2=2;, score=0.845 total time=   0.5s\n",
      "[CV 1/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 1/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.990 total time=   0.5s\n",
      "[CV 2/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 2/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.798 total time=   0.5s\n",
      "[CV 3/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 3/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.718 total time=   0.5s\n",
      "[CV 4/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 4/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.835 total time=   0.5s\n",
      "[CV 5/5; 5/9] START neuron1=8, neuron2=4........................................\n",
      "[CV 5/5; 5/9] END .........neuron1=8, neuron2=4;, score=0.835 total time=   0.6s\n",
      "[CV 1/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 1/5; 6/9] END .........neuron1=8, neuron2=8;, score=1.000 total time=   0.4s\n",
      "[CV 2/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 2/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.808 total time=   0.4s\n",
      "[CV 3/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 3/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.796 total time=   0.5s\n",
      "[CV 4/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 4/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.845 total time=   0.5s\n",
      "[CV 5/5; 6/9] START neuron1=8, neuron2=8........................................\n",
      "[CV 5/5; 6/9] END .........neuron1=8, neuron2=8;, score=0.854 total time=   0.4s\n",
      "[CV 1/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 1/5; 7/9] END ........neuron1=16, neuron2=2;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 2/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.827 total time=   0.5s\n",
      "[CV 3/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 3/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.806 total time=   0.5s\n",
      "[CV 4/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 4/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.903 total time=   0.5s\n",
      "[CV 5/5; 7/9] START neuron1=16, neuron2=2.......................................\n",
      "[CV 5/5; 7/9] END ........neuron1=16, neuron2=2;, score=0.864 total time=   0.5s\n",
      "[CV 1/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 1/5; 8/9] END ........neuron1=16, neuron2=4;, score=1.000 total time=   0.6s\n",
      "[CV 2/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 2/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.817 total time=   0.4s\n",
      "[CV 3/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 3/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.825 total time=   0.5s\n",
      "[CV 4/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 4/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.932 total time=   0.5s\n",
      "[CV 5/5; 8/9] START neuron1=16, neuron2=4.......................................\n",
      "[CV 5/5; 8/9] END ........neuron1=16, neuron2=4;, score=0.874 total time=   0.5s\n",
      "[CV 1/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 1/5; 9/9] END ........neuron1=16, neuron2=8;, score=1.000 total time=   0.5s\n",
      "[CV 2/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 2/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.856 total time=   0.5s\n",
      "[CV 3/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 3/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.883 total time=   0.5s\n",
      "[CV 4/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 4/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.913 total time=   0.5s\n",
      "[CV 5/5; 9/9] START neuron1=16, neuron2=8.......................................\n",
      "[CV 5/5; 9/9] END ........neuron1=16, neuron2=8;, score=0.913 total time=   0.5s\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
    "\n",
    "# Define the grid search parameters\n",
    "\n",
    "neuron1 = [4,8,16]\n",
    "neuron2 = [2,4,8]\n",
    "\n",
    "# Make a dictionary of the grid search parameters\n",
    "\n",
    "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "# Build and fit the GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
    "grid_result = grid.fit(X_standardized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fe964893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best : 0.9129014253616333, using {'neuron1': 16, 'neuron2': 8}\n",
      "0.7558252334594726,0.12572347563679936 with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7694174766540527,0.13110391653636874 with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7907953500747681,0.10441872133228354 with: {'neuron1': 4, 'neuron2': 8}\n",
      "0.839227044582367,0.0736230465106564 with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.8353622198104859,0.08842142269890763 with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.860567593574524,0.07305149031077991 with: {'neuron1': 8, 'neuron2': 8}\n",
      "0.8799477219581604,0.06855297312981053 with: {'neuron1': 16, 'neuron2': 2}\n",
      "0.8896751284599305,0.06871287345148008 with: {'neuron1': 16, 'neuron2': 4}\n",
      "0.9129014253616333,0.04840482765166714 with: {'neuron1': 16, 'neuron2': 8}\n"
     ]
    }
   ],
   "source": [
    "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "37dd9a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(8,input_dim = 30,kernel_initializer = 'normal',activation = 'linear'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1,activation = 'linear'))\n",
    "    \n",
    "    adam = Adam(lr = 0.01) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c174ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 2s 639us/step\n",
      "0.9013539651837524\n"
     ]
    }
   ],
   "source": [
    "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 100)\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "model.fit(X_standardized,y)\n",
    "\n",
    "# Predicting using trained model\n",
    "\n",
    "y_predict = model.predict(X_standardized)\n",
    "\n",
    "# Printing the metrics\n",
    "print(accuracy_score(y,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe12b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
